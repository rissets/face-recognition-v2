#!/usr/bin/env python3
"""
Ultra Advanced Anti-Spoofing dengan pre-trained models dan InsightFace
"""

import cv2
import numpy as np
import time
import logging
import os
from pathlib import Path
import insightface
from insightface.app import FaceAnalysis
try:
    import onnxruntime as ort
    ONNX_AVAILABLE = True
except ImportError:
    ONNX_AVAILABLE = False

# Konfigurasi logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('ultra_antispoof_log.txt'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class UltraAntiSpoofingDetector:
    def __init__(self):
        logger.info("Inisialisasi Ultra Anti-Spoofing Detector...")
        
        # Disable model downloads untuk menghindari error
        self.use_external_models = False
        
        # Statistik
        self.frame_count = 0
        self.detection_count = 0
        self.real_count = 0
        self.fake_count = 0
        self.confidence_threshold = 0.7
        
        # History untuk temporal analysis
        self.face_history = []
        self.max_history = 15
        
        # Konfigurasi deteksi
        self.min_face_size = 100
        self.detection_confidence = 0.6
        
        # Initialize webcam dengan konfigurasi optimal
        self.init_camera()
        
        # Initialize InsightFace
        self.init_insightface()
        
        # Initialize models
        self.init_models()
        
        logger.info("Ultra Detector berhasil diinisialisasi!")
        
    def init_camera(self):
        """Initialize camera dengan pengaturan optimal"""
        self.cap = cv2.VideoCapture(0)
        if not self.cap.isOpened():
            # Coba camera lain
            for i in range(1, 4):
                self.cap = cv2.VideoCapture(i)
                if self.cap.isOpened():
                    logger.info(f"Menggunakan camera index {i}")
                    break
            else:
                raise Exception("Tidak dapat membuka webcam")
        
        # Set konfigurasi optimal untuk realtime
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.cap.set(cv2.CAP_PROP_FPS, 30)
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        # Realtime optimization
        self.frame_skip = 2  # Process every 2nd frame
        self.current_skip = 0
        
        # Verifikasi pengaturan
        actual_width = self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)
        actual_height = self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
        actual_fps = self.cap.get(cv2.CAP_PROP_FPS)
        
        logger.info(f"Camera resolution: {actual_width}x{actual_height} @ {actual_fps}fps")
        
    def init_insightface(self):
        """Initialize InsightFace dengan konfigurasi optimal"""
        try:
            logger.info("Memuat InsightFace models...")
            
            # Deteksi GPU (simplified)
            providers = ['CPUExecutionProvider']
            if ONNX_AVAILABLE:
                try:
                    available_providers = ort.get_available_providers()
                    if 'CUDAExecutionProvider' in available_providers:
                        providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
                        logger.info("GPU CUDA tersedia, menggunakan GPU acceleration")
                    elif 'CoreMLExecutionProvider' in available_providers:
                        providers = ['CoreMLExecutionProvider', 'CPUExecutionProvider']
                        logger.info("CoreML tersedia, menggunakan Metal acceleration")
                except:
                    pass
            
            self.face_app = FaceAnalysis(
                providers=providers,
                allowed_modules=['detection', 'recognition', 'genderage']
            )
            self.face_app.prepare(ctx_id=0, det_size=(320, 320), det_thresh=0.5)
            logger.info("‚úì InsightFace berhasil dimuat dengan optimal settings")
            
        except Exception as e:
            logger.error(f"Error loading InsightFace: {e}")
            # Fallback multiple cascade untuk akurasi lebih baik
            self.face_app = None
            self.init_opencv_cascades()
    
    def init_opencv_cascades(self):
        """Initialize multiple OpenCV cascades untuk fallback"""
        try:
            self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            self.profile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_profileface.xml')
            self.eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
            logger.info("‚úì OpenCV cascades loaded sebagai fallback")
        except Exception as e:
            logger.error(f"Error loading OpenCV cascades: {e}")
    
    def download_model(self, model_name, url, filename):
        """Download model jika belum ada (disabled untuk menghindari error)"""
        logger.info(f"Model download disabled untuk {model_name}")
        return None
    
    def init_models(self):
        """Initialize semua models yang diperlukan"""
        try:
            # Download models yang diperlukan
            logger.info("Checking dan downloading models...")
            
            # Untuk demo, kita buat model sederhana
            self.antispoofing_model = None
            self.quality_model = None
            
            # Buat direktori models
            os.makedirs("models", exist_ok=True)
            
            logger.info("‚úì Models initialized (menggunakan heuristic analysis)")
            
        except Exception as e:
            logger.error(f"Error initializing models: {e}")
            self.antispoofing_model = None
            self.quality_model = None
    
    def detect_faces_ultra(self, frame):
        """Ultra-accurate face detection"""
        if self.face_app is not None:
            return self.detect_faces_insightface(frame)
        else:
            return self.detect_faces_opencv_enhanced(frame)
    
    def detect_faces_insightface(self, frame):
        """Enhanced InsightFace detection"""
        try:
            faces = self.face_app.get(frame)
            face_data = []
            
            for face in faces:
                bbox = face.bbox.astype(int)
                x, y, x2, y2 = bbox
                w, h = x2 - x, y2 - y
                
                # Filter berdasarkan ukuran dan confidence
                if w >= self.min_face_size and h >= self.min_face_size and face.det_score >= self.detection_confidence:
                    face_info = {
                        'bbox': (x, y, w, h),
                        'confidence': face.det_score,
                        'embedding': face.embedding,
                        'landmarks': face.kps,
                        'age': getattr(face, 'age', None),
                        'gender': getattr(face, 'gender', None),
                        'quality_score': self.calculate_face_quality(frame[y:y+h, x:x+w])
                    }
                    face_data.append(face_info)
            
            # Sort by confidence
            face_data.sort(key=lambda x: x['confidence'], reverse=True)
            return face_data
            
        except Exception as e:
            logger.debug(f"InsightFace detection error: {e}")
            return self.detect_faces_opencv_enhanced(frame)
    
    def detect_faces_opencv_enhanced(self, frame):
        """Enhanced OpenCV detection dengan multiple cascades"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Histogram equalization untuk pencahayaan yang lebih baik
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        gray = clahe.apply(gray)
        
        # Multiple scale detection
        faces = []
        
        # Frontal face detection
        frontal_faces = self.face_cascade.detectMultiScale(
            gray, 1.1, 4, minSize=(self.min_face_size, self.min_face_size)
        )
        
        for (x, y, w, h) in frontal_faces:
            # Validate dengan eye detection
            face_roi = gray[y:y+h, x:x+w]
            eyes = self.eye_cascade.detectMultiScale(face_roi)
            
            quality_score = self.calculate_face_quality(frame[y:y+h, x:x+w])
            
            face_info = {
                'bbox': (x, y, w, h),
                'confidence': 0.8 if len(eyes) >= 2 else 0.6,
                'embedding': None,
                'landmarks': None,
                'age': None,
                'gender': None,
                'quality_score': quality_score,
                'eye_count': len(eyes)
            }
            faces.append(face_info)
        
        return faces
    
    def calculate_face_quality(self, face_roi):
        """Calculate overall face quality score"""
        if face_roi.size == 0:
            return 0.0
        
        gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
        
        # Sharpness (Laplacian variance)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        
        # Brightness check
        brightness = np.mean(gray)
        brightness_score = 1.0 - abs(brightness - 128) / 128.0
        
        # Contrast
        contrast = np.std(gray) / (np.mean(gray) + 1e-7)
        
        # Combined quality score
        quality = (laplacian_var / 500.0) * 0.5 + brightness_score * 0.3 + min(contrast, 1.0) * 0.2
        return min(quality, 1.0)
    
    def extract_ultra_features(self, face_roi):
        """Extract comprehensive features untuk ultra detection"""
        if face_roi.size == 0:
            return np.zeros(30)
        
        features = []
        
        # Convert to different color spaces
        gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
        hsv = cv2.cvtColor(face_roi, cv2.COLOR_BGR2HSV)
        lab = cv2.cvtColor(face_roi, cv2.COLOR_BGR2LAB)
        yuv = cv2.cvtColor(face_roi, cv2.COLOR_BGR2YUV)
        
        # 1. Advanced Texture Features
        # Multiple kernel Laplacian
        for kernel_size in [3, 5, 7]:
            laplacian = cv2.Laplacian(gray, cv2.CV_64F, ksize=kernel_size)
            features.append(np.var(laplacian))
        
        # Sobel gradients in multiple directions
        sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        sobel_mag = np.sqrt(sobel_x**2 + sobel_y**2)
        features.extend([np.mean(sobel_mag), np.std(sobel_mag), np.max(sobel_mag)])
        
        # 2. Local Binary Pattern variations
        for radius in [1, 2, 3]:
            lbp = self.calculate_lbp_advanced(gray, radius, 8*radius)
            features.extend([np.mean(lbp), np.std(lbp)])
        
        # 3. Multi-channel color analysis
        for channel_set, name in [(hsv, 'HSV'), (lab, 'LAB'), (yuv, 'YUV')]:
            for i in range(3):
                channel = channel_set[:,:,i]
                features.extend([np.mean(channel), np.std(channel)])
        
        # 4. Frequency domain analysis
        f_transform = np.fft.fft2(gray)
        magnitude = np.abs(f_transform)
        features.extend([np.mean(magnitude), np.std(magnitude)])
        
        # 5. Wavelet-like analysis (using pyramid)
        pyramid_levels = 3
        current = gray.astype(np.float32)
        for level in range(pyramid_levels):
            current = cv2.pyrDown(current)
            features.append(np.var(current))
        
        return np.array(features[:30])  # Ensure fixed size
    
    def calculate_lbp_advanced(self, gray, radius, n_points):
        """Advanced LBP calculation"""
        h, w = gray.shape
        lbp = np.zeros_like(gray, dtype=np.uint8)
        
        for i in range(radius, h - radius):
            for j in range(radius, w - radius):
                center = gray[i, j]
                binary_code = 0
                
                for p in range(n_points):
                    angle = 2 * np.pi * p / n_points
                    x = int(round(i + radius * np.cos(angle)))
                    y = int(round(j + radius * np.sin(angle)))
                    
                    if 0 <= x < h and 0 <= y < w:
                        if gray[x, y] >= center:
                            binary_code |= (1 << p)
                
                lbp[i, j] = binary_code
        
        return lbp
    
    def ultra_spoof_detection(self, face_roi, face_info):
        """Ultra-advanced spoof detection dengan multiple algorithms"""
        
        # Extract comprehensive features
        features = self.extract_ultra_features(face_roi)
        
        # Quality-based pre-filtering
        quality_score = face_info.get('quality_score', 0.5)
        if quality_score < 0.3:
            return {
                'is_real': False,
                'confidence': 0.2,
                'reason': 'Low quality image',
                'method': 'Quality Filter'
            }
        
        # Multi-algorithm ensemble
        algorithms = []
        
        # Algorithm 1: Enhanced Texture Analysis
        texture_result = self.texture_based_detection(features, face_roi)
        algorithms.append(('Texture', texture_result))
        
        # Algorithm 2: Color Distribution Analysis
        color_result = self.color_based_detection(face_roi)
        algorithms.append(('Color', color_result))
        
        # Algorithm 3: Frequency Analysis
        freq_result = self.frequency_based_detection(face_roi)
        algorithms.append(('Frequency', freq_result))
        
        # Algorithm 4: Temporal Consistency
        temporal_result = self.temporal_consistency_check(features, face_info)
        algorithms.append(('Temporal', temporal_result))
        
        # Algorithm 5: Landmark-based (if available)
        if face_info.get('landmarks') is not None:
            landmark_result = self.landmark_based_detection(face_info['landmarks'], face_roi.shape)
            algorithms.append(('Landmark', landmark_result))
        
        # Ensemble decision
        real_votes = sum(1 for _, result in algorithms if result['is_real'])
        total_votes = len(algorithms)
        
        # Weighted confidence
        weighted_confidence = sum(result['confidence'] * 
                                (1.0 if result['is_real'] else -1.0) 
                                for _, result in algorithms) / total_votes
        
        # Final decision
        is_real = real_votes >= (total_votes * 0.6)  # 60% consensus
        final_confidence = abs(weighted_confidence)
        
        # Determine primary method
        best_algorithm = max(algorithms, key=lambda x: x[1]['confidence'])
        primary_method = best_algorithm[0]
        
        return {
            'is_real': is_real,
            'confidence': final_confidence,
            'real_votes': real_votes,
            'total_votes': total_votes,
            'consensus': real_votes / total_votes,
            'algorithms': {name: result for name, result in algorithms},
            'method': f'Ensemble ({primary_method})',
            'quality_score': quality_score
        }
    
    def texture_based_detection(self, features, face_roi):
        """Texture-based spoof detection"""
        # Advanced thresholds based on feature analysis
        texture_score = features[0]  # Primary Laplacian variance
        edge_strength = features[3]  # Sobel magnitude mean
        
        # Multi-criteria texture analysis
        is_real = (texture_score > 120 and edge_strength > 15)
        confidence = min((texture_score / 200.0) * (edge_strength / 30.0), 1.0)
        
        return {'is_real': is_real, 'confidence': confidence}
    
    def color_based_detection(self, face_roi):
        """Color distribution based detection"""
        hsv = cv2.cvtColor(face_roi, cv2.COLOR_BGR2HSV)
        
        # Analyze skin tone consistency
        hue_std = np.std(hsv[:,:,0])
        sat_mean = np.mean(hsv[:,:,1])
        val_std = np.std(hsv[:,:,2])
        
        # Real faces typically have more color variation
        color_diversity = hue_std + val_std
        skin_consistency = 1.0 / (1.0 + abs(sat_mean - 100))
        
        is_real = color_diversity > 20 and sat_mean > 30
        confidence = min(color_diversity / 50.0, 1.0) * skin_consistency
        
        return {'is_real': is_real, 'confidence': confidence}
    
    def frequency_based_detection(self, face_roi):
        """Frequency domain analysis"""
        gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
        
        # FFT analysis
        f_transform = np.fft.fft2(gray)
        f_shift = np.fft.fftshift(f_transform)
        magnitude = np.abs(f_shift)
        
        # High frequency content (real faces have more)
        h, w = magnitude.shape
        center_h, center_w = h//2, w//2
        high_freq_region = magnitude[center_h-h//4:center_h+h//4, center_w-w//4:center_w+w//4]
        high_freq_energy = np.mean(high_freq_region)
        
        is_real = high_freq_energy > 50
        confidence = min(high_freq_energy / 100.0, 1.0)
        
        return {'is_real': is_real, 'confidence': confidence}
    
    def temporal_consistency_check(self, features, face_info):
        """Check temporal consistency across frames"""
        # Add to history
        self.face_history.append({
            'features': features,
            'timestamp': time.time(),
            'bbox': face_info['bbox']
        })
        
        # Maintain history size
        if len(self.face_history) > self.max_history:
            self.face_history.pop(0)
        
        if len(self.face_history) < 3:
            return {'is_real': True, 'confidence': 0.5}
        
        # Calculate temporal stability
        recent_features = np.array([h['features'] for h in self.face_history[-5:]])
        temporal_variance = np.mean(np.var(recent_features, axis=0))
        
        # Real faces should have consistent features
        stability_score = 1.0 / (1.0 + temporal_variance)
        is_real = stability_score > 0.3
        
        return {'is_real': is_real, 'confidence': stability_score}
    
    def landmark_based_detection(self, landmarks, face_shape):
        """Landmark-based authenticity check"""
        if landmarks is None or len(landmarks) < 5:
            return {'is_real': True, 'confidence': 0.5}
        
        try:
            # Geometric analysis
            face_height, face_width = face_shape[:2]
            landmarks = landmarks.astype(int)
            
            # Calculate proportions
            left_eye = landmarks[0]
            right_eye = landmarks[1]
            nose = landmarks[2]
            
            eye_distance = np.linalg.norm(right_eye - left_eye)
            eye_ratio = eye_distance / face_width
            
            # Face symmetry
            face_center_x = face_width / 2
            eye_center_x = (left_eye[0] + right_eye[0]) / 2
            symmetry_score = 1.0 - abs(eye_center_x - face_center_x) / face_center_x
            
            # Proportion check
            proportion_ok = 0.25 <= eye_ratio <= 0.4
            symmetry_ok = symmetry_score > 0.8
            
            is_real = proportion_ok and symmetry_ok
            confidence = symmetry_score * (1.0 if proportion_ok else 0.7)
            
            return {'is_real': is_real, 'confidence': confidence}
            
        except Exception as e:
            logger.debug(f"Landmark analysis error: {e}")
            return {'is_real': True, 'confidence': 0.5}
    
    def run(self):
        """Main ultra detection loop"""
        logger.info("Memulai Ultra Anti-Spoofing Detection...")
        print("\n" + "="*60)
        print("           ULTRA ANTI-SPOOFING DETECTOR")
        print("="*60)
        print("Fitur Canggih:")
        print("‚úì InsightFace Ultra-Accurate Detection")
        print("‚úì Multi-Algorithm Ensemble Analysis")
        print("‚úì Temporal Consistency Checking")
        print("‚úì Advanced Texture & Color Analysis")
        print("‚úì Frequency Domain Analysis")
        print("‚úì Real-time Quality Assessment")
        print("\nKontrol:")
        print("q=quit | s=screenshot | d=debug | r=reset")
        print("t=threshold | h=history | c=camera settings")
        print("="*60 + "\n")
        
        prev_frame_time = 0
        debug_mode = False
        show_detailed_info = False
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                logger.error("Gagal membaca frame dari camera")
                break
            
            self.frame_count += 1
            frame = cv2.flip(frame, 1)  # Mirror effect
            
            # Calculate FPS
            new_frame_time = time.time()
            if prev_frame_time != 0:
                fps = 1 / (new_frame_time - prev_frame_time)
            else:
                fps = 0
            prev_frame_time = new_frame_time
            
            # Status
            status_text = "üîç Mencari wajah..."
            status_color = (255, 255, 0)  # Yellow
            
            # Ultra face detection
            faces = self.detect_faces_ultra(frame)
            
            if faces:
                self.detection_count += 1
                
                for i, face_info in enumerate(faces):
                    x, y, w, h = face_info['bbox']
                    detection_confidence = face_info['confidence']
                    quality_score = face_info['quality_score']
                    
                    # Extract enhanced face ROI
                    padding = max(20, int(min(w, h) * 0.1))
                    x1 = max(0, x - padding)
                    y1 = max(0, y - padding)
                    x2 = min(frame.shape[1], x + w + padding)
                    y2 = min(frame.shape[0], y + h + padding)
                    
                    face_roi = frame[y1:y2, x1:x2]
                    
                    if face_roi.size > 0:
                        # Ultra spoof detection
                        result = self.ultra_spoof_detection(face_roi, face_info)
                        
                        is_real = result['is_real']
                        confidence = result['confidence']
                        method = result['method']
                        consensus = result['consensus']
                        
                        # Update statistics
                        if is_real:
                            self.real_count += 1
                            label = f"‚úÖ ASLI ({confidence:.2f})"
                            color = (0, 255, 0)  # Green
                            status_text = f"‚úÖ WAJAH ASLI TERDETEKSI (Consensus: {consensus:.1%})"
                            status_color = (0, 255, 0)
                        else:
                            self.fake_count += 1
                            label = f"‚ùå PALSU ({confidence:.2f})"
                            color = (0, 0, 255)  # Red
                            status_text = f"‚ùå WAJAH PALSU TERDETEKSI (Consensus: {consensus:.1%})"
                            status_color = (0, 0, 255)
                        
                        # Draw enhanced bounding box
                        thickness = 4 if is_real else 3
                        cv2.rectangle(frame, (x, y), (x+w, y+h), color, thickness)
                        
                        # Enhanced labels
                        cv2.putText(frame, label, (x, y-20), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
                        cv2.putText(frame, f"Quality: {quality_score:.2f}", (x, y+h+25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
                        cv2.putText(frame, f"Votes: {result['real_votes']}/{result['total_votes']}", (x, y+h+45), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
                        
                        # Debug information
                        if debug_mode:
                            algorithms = result['algorithms']
                            y_offset = y + h + 70
                            for name, algo_result in algorithms.items():
                                status = "‚úì" if algo_result['is_real'] else "‚úó"
                                cv2.putText(frame, f"{status} {name}: {algo_result['confidence']:.2f}", 
                                          (x, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)
                                y_offset += 15
                        
                        # Draw landmarks if available
                        if face_info.get('landmarks') is not None and debug_mode:
                            for landmark in face_info['landmarks']:
                                cv2.circle(frame, tuple(landmark.astype(int)), 3, (255, 255, 0), -1)
                        
                        # Log detailed result
                        logger.info(f"Frame {self.frame_count}: {'ASLI' if is_real else 'PALSU'} - "
                                  f"Confidence: {confidence:.3f}, Quality: {quality_score:.2f}, "
                                  f"Consensus: {consensus:.1%}, Method: {method}")
            
            # Draw ultra UI
            self.draw_ultra_ui(frame, fps, status_text, status_color, debug_mode, show_detailed_info)
            
            # Show frame
            window_name = "üöÄ Ultra Anti-Spoofing Detection"
            cv2.imshow(window_name, frame)
            
            # Handle key presses
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                logger.info("Aplikasi dihentikan oleh user")
                break
            elif key == ord('s'):
                timestamp = int(time.time())
                screenshot_name = f"ultra_screenshot_{timestamp}.jpg"
                cv2.imwrite(screenshot_name, frame)
                logger.info(f"Screenshot saved: {screenshot_name}")
                print(f"üì∏ Screenshot disimpan: {screenshot_name}")
            elif key == ord('d'):
                debug_mode = not debug_mode
                logger.info(f"Debug mode: {'ON' if debug_mode else 'OFF'}")
                print(f"üêõ Debug mode: {'ON' if debug_mode else 'OFF'}")
            elif key == ord('i'):
                show_detailed_info = not show_detailed_info
                print(f"‚ÑπÔ∏è  Detailed info: {'ON' if show_detailed_info else 'OFF'}")
            elif key == ord('r'):
                self.reset_statistics()
            elif key == ord('t'):
                self.adjust_threshold()
            elif key == ord('c'):
                self.adjust_camera_settings()
    
    def draw_ultra_ui(self, frame, fps, status_text, status_color, debug_mode, show_detailed_info):
        """Draw ultra-modern UI"""
        h, w = frame.shape[:2]
        
        # Modern dark panel with transparency effect
        panel_height = 250 if debug_mode else 200
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (500, panel_height), (30, 30, 30), -1)
        cv2.addWeighted(overlay, 0.8, frame, 0.2, 0, frame)
        
        # Border with gradient effect
        cv2.rectangle(frame, (10, 10), (500, panel_height), (100, 100, 255), 3)
        
        # Title
        cv2.putText(frame, "ULTRA ANTI-SPOOFING", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100, 255, 255), 2)
        
        # Performance metrics
        cv2.putText(frame, f"FPS: {int(fps)}", (20, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        cv2.putText(frame, f"Frame: {self.frame_count}", (150, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(frame, f"Engine: InsightFace+", (300, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # Detection statistics with icons
        cv2.putText(frame, f"üéØ Total: {self.detection_count}", (20, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(frame, f"‚úÖ Real: {self.real_count}", (20, 125), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        cv2.putText(frame, f"‚ùå Fake: {self.fake_count}", (150, 125), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
        
        # Accuracy percentage
        if self.detection_count > 0:
            real_pct = (self.real_count / self.detection_count) * 100
            fake_pct = (self.fake_count / self.detection_count) * 100
            cv2.putText(frame, f"üìä Real: {real_pct:.1f}% | Fake: {fake_pct:.1f}%", (20, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        
        # System status
        cv2.putText(frame, f"‚öôÔ∏è  Threshold: {self.confidence_threshold:.2f}", (20, 175), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(frame, f"üìã History: {len(self.face_history)}/{self.max_history}", (250, 175), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # Mode indicators
        indicators = []
        if debug_mode:
            indicators.append("üêõ DEBUG")
        if show_detailed_info:
            indicators.append("‚ÑπÔ∏è  DETAIL")
        
        if indicators:
            cv2.putText(frame, " | ".join(indicators), (w-200, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)
        
        # Main status with enhanced styling
        status_bg = (0, 0, 0)
        cv2.rectangle(frame, (10, h-80), (w-10, h-10), status_bg, -1)
        cv2.rectangle(frame, (10, h-80), (w-10, h-10), status_color, 2)
        cv2.putText(frame, status_text, (20, h-50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)
        
        # Controls
        controls = "q=quit | s=screenshot | d=debug | r=reset | t=threshold | c=camera"
        cv2.putText(frame, controls, (20, h-20), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (200, 200, 200), 1)
    
    def reset_statistics(self):
        """Reset all statistics"""
        self.detection_count = 0
        self.real_count = 0
        self.fake_count = 0
        self.face_history.clear()
        logger.info("üìä Semua statistik dan history direset")
        print("üìä Statistik direset!")
    
    def adjust_threshold(self):
        """Interactive threshold adjustment"""
        print(f"\n‚öôÔ∏è  Current threshold: {self.confidence_threshold}")
        print("Rekomendasi threshold:")
        print("üî¥ 0.3-0.5: Sangat sensitif (banyak deteksi fake)")
        print("üü° 0.6-0.7: Balanced (recommended)")
        print("üü¢ 0.8-0.9: Konservatif (lebih percaya real)")
        
        try:
            new_threshold = float(input("Masukkan threshold baru (0.0-1.0): "))
            if 0.0 <= new_threshold <= 1.0:
                old_threshold = self.confidence_threshold
                self.confidence_threshold = new_threshold
                logger.info(f"Threshold changed: {old_threshold} ‚Üí {new_threshold}")
                print(f"‚úÖ Threshold diupdate: {old_threshold} ‚Üí {new_threshold}")
            else:
                print("‚ùå Threshold harus antara 0.0 dan 1.0")
        except ValueError:
            print("‚ùå Input tidak valid")
        except KeyboardInterrupt:
            print("\n‚ùå Batal mengubah threshold")
    
    def adjust_camera_settings(self):
        """Interactive camera settings adjustment"""
        print("\nüì∑ Camera Settings:")
        print("1. Brightness")
        print("2. Contrast") 
        print("3. Exposure")
        print("4. Reset to default")
        
        try:
            choice = input("Pilih setting (1-4): ")
            
            if choice == '1':
                brightness = float(input("Brightness (0.0-1.0): "))
                self.cap.set(cv2.CAP_PROP_BRIGHTNESS, brightness)
                print(f"‚úÖ Brightness set to {brightness}")
                
            elif choice == '2':
                contrast = float(input("Contrast (0.0-1.0): "))
                self.cap.set(cv2.CAP_PROP_CONTRAST, contrast)
                print(f"‚úÖ Contrast set to {contrast}")
                
            elif choice == '3':
                exposure = float(input("Exposure (0.0-1.0): "))
                self.cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, exposure)
                print(f"‚úÖ Exposure set to {exposure}")
                
            elif choice == '4':
                self.cap.set(cv2.CAP_PROP_BRIGHTNESS, 0.5)
                self.cap.set(cv2.CAP_PROP_CONTRAST, 0.5)
                self.cap.set(cv2.CAP_PROP_AUTO_EXPOSURE, 0.25)
                print("‚úÖ Camera settings reset to default")
                
        except (ValueError, KeyboardInterrupt):
            print("‚ùå Pengaturan camera dibatalkan")
    
    def cleanup(self):
        """Enhanced cleanup with detailed statistics"""
        print("\n" + "="*60)
        print("           ULTRA DETECTION SESSION SUMMARY")
        print("="*60)
        
        logger.info("=== ULTRA SESSION STATISTICS ===")
        logger.info(f"Total frames processed: {self.frame_count}")
        logger.info(f"Total face detections: {self.detection_count}")
        logger.info(f"Real faces detected: {self.real_count}")
        logger.info(f"Fake faces detected: {self.fake_count}")
        
        if self.detection_count > 0:
            real_percentage = (self.real_count / self.detection_count) * 100
            fake_percentage = (self.fake_count / self.detection_count) * 100
            accuracy_est = max(real_percentage, fake_percentage)
            
            logger.info(f"Real detection rate: {real_percentage:.1f}%")
            logger.info(f"Fake detection rate: {fake_percentage:.1f}%")
            logger.info(f"Estimated accuracy: {accuracy_est:.1f}%")
            
            print(f"üìä Total Detections: {self.detection_count}")
            print(f"‚úÖ Real Faces: {self.real_count} ({real_percentage:.1f}%)")
            print(f"‚ùå Fake Faces: {self.fake_count} ({fake_percentage:.1f}%)")
            print(f"üéØ Estimated Accuracy: {accuracy_est:.1f}%")
        else:
            print("üìä No detections recorded")
        
        detection_rate = self.detection_count / max(self.frame_count, 1) * 100
        print(f"üîç Detection Rate: {detection_rate:.1f}% of frames")
        print(f"‚öôÔ∏è  Final Threshold: {self.confidence_threshold}")
        print("="*60)
        
        self.cap.release()
        cv2.destroyAllWindows()
        
        # Save session log
        session_log = {
            'timestamp': time.time(),
            'total_frames': self.frame_count,
            'total_detections': self.detection_count,
            'real_count': self.real_count,
            'fake_count': self.fake_count,
            'threshold': self.confidence_threshold
        }
        
        try:
            import json
            with open(f"ultra_session_{int(time.time())}.json", 'w') as f:
                json.dump(session_log, f, indent=2)
            print("üìù Session log saved")
        except:
            pass

def main():
    print("üöÄ ULTRA ANTI-SPOOFING SYSTEM v2.0 üöÄ")
    print("Initializing advanced systems...")
    
    try:
        detector = UltraAntiSpoofingDetector()
        detector.run()
    except KeyboardInterrupt:
        logger.info("Aplikasi dihentikan dengan Ctrl+C")
        print("\n‚èπÔ∏è  Aplikasi dihentikan oleh user")
    except Exception as e:
        logger.error(f"Critical error: {str(e)}")
        print(f"‚ùå Critical Error: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        try:
            detector.cleanup()
        except:
            pass

if __name__ == "__main__":
    main()